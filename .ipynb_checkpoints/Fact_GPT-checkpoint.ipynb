{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 19649,
     "status": "ok",
     "timestamp": 1679611472281,
     "user": {
      "displayName": "吉田昂",
      "userId": "03547491842421461424"
     },
     "user_tz": 0
    },
    "id": "I1piQykn7NSK",
    "outputId": "4da7b040-a372-4052-e8b6-1a794bf25cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.26.5)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2022.9.24)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8444,
     "status": "ok",
     "timestamp": 1679611480719,
     "user": {
      "displayName": "吉田昂",
      "userId": "03547491842421461424"
     },
     "user_tz": 0
    },
    "id": "Q2HZTLxN_Tzz",
    "outputId": "348be634-e0e6-4a40-b71e-aa25e31f4dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tenacity in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (8.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1472,
     "status": "ok",
     "timestamp": 1679611482187,
     "user": {
      "displayName": "吉田昂",
      "userId": "03547491842421461424"
     },
     "user_tz": 0
    },
    "id": "CVWVRanjISLU"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import random \n",
    "import numpy\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5AnDU79ms_T"
   },
   "source": [
    "# **Document → claims**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1679612053668,
     "user": {
      "displayName": "吉田昂",
      "userId": "03547491842421461424"
     },
     "user_tz": 0
    },
    "id": "3-FCaVpTqrux"
   },
   "outputs": [],
   "source": [
    "sample_query = \"List out the factual claims made in this text: Globalist billionaire Bill Gates, who has a history of making uncannily prescient investments just before disaster strikes in the world, invested in artificial eggs before the price of eggs spiked. The mystery surrounding the egg shortage and price spike is growing. Per the Consumer Price Index, egg prices have spiked 66% percent since last year. In response to the shortage of eggs, many consumers have turned to artificial plant-based eggs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3614,
     "status": "ok",
     "timestamp": 1679612213225,
     "user": {
      "displayName": "吉田昂",
      "userId": "03547491842421461424"
     },
     "user_tz": 0
    },
    "id": "i04gJx9Xdgh3",
    "outputId": "c958ff0c-e874-4d62-b332-f2bec45f9906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy and paste some text here: Globalist billionaire Bill Gates, who has a history of making uncannily prescient investments just before disaster strikes in the world, invested in artificial eggs before the price of eggs spiked. The mystery surrounding the egg shortage and price spike is growing. Per the Consumer Price Index, egg prices have spiked 66% percent since last year. In response to the shortage of eggs, many consumers have turned to artificial plant-based eggs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['- Bill Gates invested in artificial eggs before the price of eggs spiked.',\n",
       " '- The price of eggs has spiked 66% since last year according to the Consumer Price Index.',\n",
       " '- Many consumers have turned to artificial plant-based eggs in response to the shortage of eggs.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(10)) \n",
    "#To prevent API requests from timing out, gpt_request will retry max 10 times with intervals of 1-60 seconds\n",
    "\n",
    "def gpt_request(query):\n",
    "    \n",
    "    \"\"\" Send a query to GPT-4 API and return the response \"\"\"\n",
    "    \n",
    "    endpoint = \"https://api.openai.com/v1/chat/completions\"\n",
    "    api_key = \"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\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        # We don't need system message cos we don't ask fact checking\n",
    "        \"messages\" : [{\"role\": \"user\", \"content\": query}],\n",
    "        \"max_tokens\": 2000,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, json=data)\n",
    "    response_json = response.json()\n",
    "    # print(response_json)\n",
    "    return response_json['choices'][0]['message']['content'].strip()\n",
    "\n",
    "def summarise(text): \n",
    "    query = \"Identify the factual claims made in the text below that would be of interest to fact checkers, \\\n",
    "    excluding any source attribution or contact information unless relevant to verifying another fact. \\\n",
    "    Each claim should be a self-contained sentence not dependent on context from other claims. \\\n",
    "    Leave out names of people unless they are crucial to the claim (i.e. the name is the claim) \\\n",
    "    or they are famous people. Also exclude any subjective facts (such as feelings or wishes) \\\n",
    "    that cannot be independently verified. \\n\\n\"\n",
    "    \n",
    "    return gpt_request(query + text)\n",
    "    \n",
    "# Get a list of factual claims\n",
    "user_input = str(input(\"Copy and paste some text here: \"))\n",
    "responses = summarise(user_input)\n",
    "if \"\\n\" in responses:\n",
    "    responses = responses.split(\"\\n\")\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Optimise following claim to search for relevant content in Google Fact Check Explorer: - Bill Gates invested in artificial eggs before the price of eggs spiked.',\n",
       " 'Optimise following claim to search for relevant content in Google Fact Check Explorer: - The price of eggs has spiked 66% since last year according to the Consumer Price Index.',\n",
       " 'Optimise following claim to search for relevant content in Google Fact Check Explorer: - Many consumers have turned to artificial plant-based eggs in response to the shortage of eggs.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify claims in a certain style that can be requested to AI\n",
    "modified_claims = []\n",
    "for response in responses:\n",
    "    response = 'Optimise following claim to search for relevant content in Google Fact Check Explorer: ' + response\n",
    "    modified_claims.append(response)\n",
    "\n",
    "modified_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Bill Gates investment in artificial eggs before egg price increase\"',\n",
       " '\"Consumer Price Index reports 66% increase in egg prices since last year\"',\n",
       " '\"Artificial plant-based eggs as a response to egg shortage - fact check\"']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask AI for optimizing claims\n",
    "optimized_claims = []\n",
    "for i in modified_claims:\n",
    "    response = gpt_request(i)\n",
    "    optimized_claims.append(response)\n",
    "    \n",
    "optimized_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woKhSyfon4vB"
   },
   "source": [
    "# Search Data Commons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://factchecktools.googleapis.com/v1alpha1/claims:search?query=\"Fact check: Did Bill Gates invest in artificial eggs?\"&languageCode=en&maxAgeDays=10000&key=AIzaSyAAB8N8l47u7kt_EfrPFUKpwfOPYRmIlGw&pageSize=10000',\n",
       " 'https://factchecktools.googleapis.com/v1alpha1/claims:search?query=\"Bill Gates prescient investments before disasters\"&languageCode=en&maxAgeDays=10000&key=AIzaSyAAB8N8l47u7kt_EfrPFUKpwfOPYRmIlGw&pageSize=10000',\n",
       " 'https://factchecktools.googleapis.com/v1alpha1/claims:search?query=\"Fact check: Has the price of eggs spiked recently?\"&languageCode=en&maxAgeDays=10000&key=AIzaSyAAB8N8l47u7kt_EfrPFUKpwfOPYRmIlGw&pageSize=10000',\n",
       " 'https://factchecktools.googleapis.com/v1alpha1/claims:search?query=\"Egg shortage mystery\" fact check&languageCode=en&maxAgeDays=10000&key=AIzaSyAAB8N8l47u7kt_EfrPFUKpwfOPYRmIlGw&pageSize=10000',\n",
       " 'https://factchecktools.googleapis.com/v1alpha1/claims:search?query=\"Consumer Price Index egg prices 66% increase last year\"&languageCode=en&maxAgeDays=10000&key=AIzaSyAAB8N8l47u7kt_EfrPFUKpwfOPYRmIlGw&pageSize=10000',\n",
       " 'https://factchecktools.googleapis.com/v1alpha1/claims:search?query=\"Artificial plant-based eggs used as a response to egg shortage - fact check\"&languageCode=en&maxAgeDays=10000&key=AIzaSyAAB8N8l47u7kt_EfrPFUKpwfOPYRmIlGw&pageSize=10000']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melissa's header\n",
    "# my_headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36; Melissa Zhu/ZhuM17@cardiff.ac.uk. Working on data for class.'}\n",
    "# Koh's header\n",
    "my_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36 Edg/107.0.1418.56; Koh Yoshida/yoshidak1@cardiff.ac.uk. Working on data for class.'}\n",
    "\n",
    "endpoint = 'https://factchecktools.googleapis.com/v1alpha1/claims:search'\n",
    "\n",
    "links = []\n",
    "\n",
    "for i in optimized_claims:\n",
    "    \n",
    "    query = i\n",
    "    language = 'en'\n",
    "    max_days = 10000 #Max age of returned search results, in days\n",
    "    page_size = 10000 #Number of pages in the search results\n",
    "\n",
    "    # reviewPublisherSiteFilter = 'factcheck.afp.com' #Filter by review publisher\n",
    "\n",
    "    # api_key = 'AIzaSyDKpe6j4lqR_yuy6FZMI3NEdY9VP7Fa2jI' # Melissa's key\n",
    "    api_key = 'AIzaSyAAB8N8l47u7kt_EfrPFUKpwfOPYRmIlGw' # Koh's key\n",
    "\n",
    "    # url = f'{endpoint}?query={query}&languageCode={language}&maxAgeDays={max_days}&key={api_key}&pageSize={page_size}&reviewPublisherSiteFilter={reviewPublisherSiteFilter}'\n",
    "    url = f'{endpoint}?query={query}&languageCode={language}&maxAgeDays={max_days}&key={api_key}&pageSize={page_size}'\n",
    "    links.append(url)\n",
    "\n",
    "# the links below contains sesrched results,the first link is for the first claim\n",
    "# If computer got no hit with the claim, it just shows \"{}\"\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{}, {}, {}, {}, {}, {}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims = []\n",
    "for link in links:\n",
    "    req = requests.get(link, headers = my_headers)\n",
    "#     print(req.status_code)\n",
    "    data = req.json()\n",
    "    claims.append(data)\n",
    "\n",
    "claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m ratings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m claim \u001b[38;5;129;01min\u001b[39;00m claims: \n\u001b[1;32m---> 13\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43mclaim\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m     queries\u001b[38;5;241m.\u001b[39mappend(query)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m claim \u001b[38;5;129;01min\u001b[39;00m claims: \n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "queries = []\n",
    "originators = []\n",
    "claim_dates = []\n",
    "reviews = []\n",
    "publisher_names = []\n",
    "publisher_sites = []\n",
    "review_urls = []\n",
    "titles = []\n",
    "review_dates = []\n",
    "ratings = []\n",
    "\n",
    "for claim in claims: \n",
    "    query = claim['text']\n",
    "    queries.append(query)\n",
    "\n",
    "for claim in claims: \n",
    "    if 'claimant' in claim:\n",
    "        originator = claim['claimant']\n",
    "        originators.append(originator)\n",
    "    else: \n",
    "        originators.append('NA')\n",
    "    \n",
    "for claim in claims: \n",
    "    if 'claimDate' in claim:\n",
    "        date = claim['claimDate']\n",
    "        claim_dates.append(date)\n",
    "    else: \n",
    "        claim_dates.append('NA')\n",
    "\n",
    "for claim in claims: \n",
    "    first_review = claim['claimReview'][0]\n",
    "    reviews.append(first_review) #Most only have one review but some of them have many reviews all saying the same thing so gonna keep it to one to standardise the dataframe\n",
    "\n",
    "for review in reviews: \n",
    "    if 'publisher' in review and 'name' in review['publisher']: \n",
    "        publisher_name = review['publisher']['name']\n",
    "        publisher_names.append(publisher_name)\n",
    "    else: \n",
    "        publisher_names.append('NA')\n",
    "\n",
    "for review in reviews: \n",
    "    if 'publisher' in review and 'site' in review['publisher']: \n",
    "        publisher_site = review['publisher']['site']\n",
    "        publisher_sites.append(publisher_site)\n",
    "    else: \n",
    "        publisher_sites.append('NA')\n",
    "\n",
    "for review in reviews: \n",
    "    if 'url' in review: \n",
    "        review_url = review['url']\n",
    "        review_urls.append(review_url)\n",
    "    else: \n",
    "        review_urls.append('NA')\n",
    "        \n",
    "for review in reviews: \n",
    "    if 'title' in review: \n",
    "        title = review['title']\n",
    "        titles.append(title)\n",
    "    else: \n",
    "        titles.append('NA')\n",
    "\n",
    "for review in reviews: \n",
    "    if 'reviewDate' in review: \n",
    "        review_date = review['reviewDate']\n",
    "        review_dates.append(review_date)\n",
    "    else: \n",
    "        review_dates.append('NA')\n",
    "\n",
    "for review in reviews: \n",
    "    if 'textualRating' in review: \n",
    "        rating = review['textualRating']\n",
    "        ratings.append(rating)\n",
    "    else: \n",
    "        ratings.append('NA')\n",
    "        \n",
    "        \n",
    "print(queries)\n",
    "print(originators)\n",
    "print(claim_dates)\n",
    "print(publisher_names)\n",
    "print(publisher_sites)\n",
    "print(review_urls)\n",
    "print(titles)\n",
    "print(review_dates)\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a table\n",
    "df = pd.DataFrame({'claim': queries, \n",
    "                   'originator': originators, \n",
    "                   'claim_date': claim_dates, \n",
    "                   'review_publisher': publisher_names, \n",
    "                   'publisher_site': publisher_sites, \n",
    "                   'review_url': review_urls, \n",
    "                   'review_title': titles, \n",
    "                   'review_date': review_dates, \n",
    "                   'verdict': ratings})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto scraping (python library \"newspaper\")\n",
    "### Just copied and pasted code from the documentation (https://newspaper.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.8)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (9.3.0)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (2.8.2)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (6.0.10)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (4.11.1)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (4.9.2)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (6.0)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (3.4.0)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (2.28.1)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from newspaper3k) (3.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.3.2.post1)\n",
      "Requirement already satisfied: six in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2022.10.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.1.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ukoda\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "sample = newspaper.build('https://www.snopes.com/fact-check/alligator-eats-girl-photo/', language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alligator Eats Girl Taking Photograph?\n",
      "Advertisment:\n",
      "\n",
      "Claim: Video shows a woman getting eaten by an alligator while posing for a photograph along a riverbank. Rating: About this rating False\n",
      "\n",
      "A video purportedly showing a woman being attacked by an alligator while posing for a photograph along a riverbank has been circulating on the Internet since 2012.\n",
      "\n",
      "The video does not show a real alligator attack, however: it's merely a commercial for Preview magazine.\n",
      "\n",
      "When the video was originally uploaded to YouTube, it featured a few extra seconds of footage containing the tagline \"choose your bag wisely,\" the hashtag #IMAPreviewGirl, and a link to Preview's web site. These aspects clearly identified the video as an advertisement; but (as is typical with such \"reality\" commercials) they were trimmed off by those who subsequently reposted it, making it difficult for viewers to recognize the clip as a commercial.\n",
      "\n",
      "Although several versions of this video currently circulating on the Internet (many lacking the final seconds of the original video) claim to depict a real alligator attack, Preview has made it clear that this clip (\"How Not to Instagram\") is just a commercial. The magazine has listed the full creative team behind the clip on their web site, and the viral video has won a few advertising awards:\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "url = 'https://www.snopes.com/fact-check/alligator-eats-girl-photo/'\n",
    "\n",
    "a = Article(url, language='en') \n",
    "\n",
    "a.download()\n",
    "a.parse()\n",
    "\n",
    "title = a.title\n",
    "contents = a.text[:10000]\n",
    "\n",
    "print(title)\n",
    "print(a.text[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summarize following contents within 50 words, focusing on reasons for its verdict: Advertisment:\\n\\nClaim: Video shows a woman getting eaten by an alligator while posing for a photograph along a riverbank. Rating: About this rating False\\n\\nA video purportedly showing a woman being attacked by an alligator while posing for a photograph along a riverbank has been circulating on the Internet since 2012.\\n\\nThe video does not show a real alligator attack, however: it\\'s merely a commercial for Preview magazine.\\n\\nWhen the video was originally uploaded to YouTube, it featured a few extra seconds of footage containing the tagline \"choose your bag wisely,\" the hashtag #IMAPreviewGirl, and a link to Preview\\'s web site. These aspects clearly identified the video as an advertisement; but (as is typical with such \"reality\" commercials) they were trimmed off by those who subsequently reposted it, making it difficult for viewers to recognize the clip as a commercial.\\n\\nAlthough several versions of this video currently circulating on the Internet (many lacking the final seconds of the original video) claim to depict a real alligator attack, Preview has made it clear that this clip (\"How Not to Instagram\") is just a commercial. The magazine has listed the full creative team behind the clip on their web site, and the viral video has won a few advertising awards:'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask AI to summarize scraped contents\n",
    "modified_contents = f'Summarize following contents within 50 words, focusing on reasons for its verdict: {contents}'\n",
    "modified_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A video circulating on the internet since 2012, which appears to show a woman being attacked by an alligator while posing for a photograph, has been rated as false. The video is actually a commercial for Preview magazine, but the tagline and link to the magazine's website were trimmed off by those who subsequently reposted it, making it difficult for viewers to recognise it as an advertisement. Preview has made it clear that the clip is just a commercial and has listed the full creative team behind the clip on its website.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "send_request(modified_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1t7c0cIgNfjE3iu2lxjoUKtZKU1K8-2a3",
     "timestamp": 1677972250438
    },
    {
     "file_id": "1nbWrlLEVXVXa2rRKqBdn2Jbd5fJhHcRy",
     "timestamp": 1677150908273
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
